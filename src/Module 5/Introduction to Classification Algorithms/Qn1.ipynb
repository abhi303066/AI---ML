{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Classfication<br>\n",
    "\n",
    "Task 1:<br>\n",
    "Objective: Identify if an email is spam or not spam.<br>\n",
    "Load the UCI Spambase Dataset.<br>\n",
    "Goal: Create a model that classifies emails into two categories: \"spam\" and \"not spam.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "\n",
      "Warning: Missing values found. Handling by dropping rows with NaNs.\n",
      "Shape of DataFrame after dropping NaNs: (0, 106)\n",
      "An error occurred: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
      "Please ensure you have a stable internet connection or download the dataset manually.\n",
      "If downloading manually, replace the 'url' variable with the path to your local file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset from the UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "column_names = [f\"feature_{i}\" for i in range(48)] + \\\n",
    "               [f\"word_freq_{word}\" for word in ['make', 'address', 'all', '3d', 'our', 'over', 'remove',\n",
    "                                                  'internet', 'order', 'mail', 'receive', 'will', 'people',\n",
    "                                                  'report', 'addresses', 'free', 'business', 'email', 'you',\n",
    "                                                  'credit', 'your', 'font', '000', 'money', 'hp', 'hpl',\n",
    "                                                  'george', '650', 'lab', 'labs', 'telnet', '857', 'data',\n",
    "                                                  '415', '85', 'technology', '1999', 'parts', 'pm', 'direct',\n",
    "                                                  'cs', 'meeting', 'original', 'project', 're', 'edu', 'table',\n",
    "                                                  'conference']] + \\\n",
    "               [f\"char_freq_{char}\" for char in [';', '(', '[', '!', '$', '#']] + \\\n",
    "               ['capital_run_length_average', 'capital_run_length_longest', 'capital_total', 'is_spam']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(url, names=column_names)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "\n",
    "    # Check for missing values\n",
    "    if df.isnull().sum().any():\n",
    "        print(\"\\nWarning: Missing values found. Handling by dropping rows with NaNs.\")\n",
    "        df.dropna(inplace=True)\n",
    "        print(f\"Shape of DataFrame after dropping NaNs: {df.shape}\")\n",
    "    else:\n",
    "        print(\"\\nNo missing values found.\")\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop('is_spam', axis=1)\n",
    "    y = df['is_spam']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Initialize and train a Logistic Regression model\n",
    "    model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=['not spam', 'spam'])\n",
    "\n",
    "    print(\"\\nModel trained and evaluated!\")\n",
    "    print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure you have a stable internet connection or download the dataset manually.\")\n",
    "    print(\"If downloading manually, replace the 'url' variable with the path to your local file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:<br>\n",
    "Objective: Diagnose whether a tumor is malignant or benign.<br>\n",
    "Load the Breast Cancer Wisconsin dataset.<br>\n",
    "Goal: Build a binary classification model to classify tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin dataset loaded successfully!\n",
      "Shape of features: (569, 30)\n",
      "Shape of target: (569,)\n",
      "\n",
      "First few rows of the dataset:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Model trained and evaluated!\n",
      "Accuracy on the test set: 0.9415\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.97      0.88      0.92        64\n",
      "   malignant       0.93      0.98      0.95       107\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.95      0.93      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Breast Cancer Wisconsin dataset\n",
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "\n",
    "print(\"Breast Cancer Wisconsin dataset loaded successfully!\")\n",
    "print(f\"Shape of features: {df.drop('target', axis=1).shape}\")\n",
    "print(f\"Shape of target: {df['target'].shape}\")\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train a Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['benign', 'malignant'])\n",
    "\n",
    "print(\"\\nModel trained and evaluated!\")\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 3:<br>\n",
    "Objective: Determine whether a transaction is fraudulent or legitimate.<br>\n",
    "Use a credit card transaction dataset.<br>\n",
    "Goal: Classify transactions into \"fraudulent\" and \"legitimate\" categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'creditcard.csv' not found. Please download the dataset from Kaggle and ensure it's in the correct directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Credit Card Fraud Detection dataset\n",
    "# This dataset is available on Kaggle: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "# You'll need to download 'creditcard.csv' and place it in the same directory as your script,\n",
    "# or provide the correct path to the file.\n",
    "try:\n",
    "    df = pd.read_csv('creditcard.csv')\n",
    "    print(\"Credit Card Fraud Detection dataset loaded successfully!\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "    print(\"\\nFirst few rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # The 'Class' column is our target variable (1 for fraudulent, 0 for legitimate)\n",
    "    X = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    # Scale the 'Amount' and 'Time' features for better model performance\n",
    "    scaler = StandardScaler()\n",
    "    X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1, 1))\n",
    "    X['Time'] = scaler.fit_transform(X['Time'].values.reshape(-1, 1))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Initialize and train a Logistic Regression model\n",
    "    # Adjust class_weight due to the imbalanced nature of the dataset\n",
    "    model = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=['legitimate', 'fraudulent'])\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nModel trained and evaluated!\")\n",
    "    print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'creditcard.csv' not found. Please download the dataset from Kaggle and ensure it's in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
